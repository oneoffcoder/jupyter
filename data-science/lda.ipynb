{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "from scipy.sparse import lil_matrix\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "# number of topics\n",
    "K = 10\n",
    "# number of words\n",
    "N = 100\n",
    "# number of documents\n",
    "M = 1000\n",
    "\n",
    "# priors on K topics\n",
    "a = np.array([0.1, 0.2, 0.3, 0.4, 0.025, 0.015, 0.37, 0.88, 0.03, 0.08])\n",
    "# priors on N words\n",
    "b = np.full((1, N), 0.001, dtype=float)[0]\n",
    "\n",
    "# distribution of words in topic k\n",
    "psi = np.array([dirichlet.rvs(b)[0] for _ in range(K)])\n",
    "\n",
    "# distribution of topics in document d\n",
    "theta = np.array([dirichlet.rvs(a)[0] for _ in range(M)])\n",
    "\n",
    "# simulate the documents\n",
    "docs = []\n",
    "for i in range(M):\n",
    "    d = {}\n",
    "    stop = False\n",
    "    for j in range(N):\n",
    "        try:\n",
    "            z_ij = multinomial.rvs(1, theta[i] / theta[i].sum())\n",
    "            topic = np.argmax(z_ij)\n",
    "        except:\n",
    "            print(i)\n",
    "            stop = True\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            w_ij = multinomial.rvs(1, psi[topic] / psi[topic].sum())\n",
    "        except:\n",
    "            print(topic)\n",
    "            print(psi[topic].sum())\n",
    "            print(psi[topic])\n",
    "            stop = True\n",
    "            break\n",
    "        word = np.argmax(w_ij)\n",
    "        \n",
    "        if word not in d:\n",
    "            d[word] = 0\n",
    "        d[word] = d[word] + 1\n",
    "    if stop == True:\n",
    "        break\n",
    "    docs.append(d)\n",
    "\n",
    "# make a nice matrix\n",
    "X = lil_matrix((M, N), dtype=np.int16)\n",
    "for i, d in enumerate(docs):\n",
    "    counts = sorted(list(d.items()), key=lambda tup: tup[0])\n",
    "    for tup in counts:\n",
    "        X[i, tup[0]] = tup[1]\n",
    "        \n",
    "tfidf = TfidfTransformer()\n",
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[109].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pvals < 0, pvals > 1 or pvals contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0f5f61e0e774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultinomial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m109\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m109\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, n, p, size, random_state)\u001b[0m\n\u001b[1;32m   3218\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcommon.pyx\u001b[0m in \u001b[0;36mnumpy.random.common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
     ]
    }
   ],
   "source": [
    "multinomial.rvs(1, theta[109] / theta[109].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi[5].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi[4].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(theta[109] / theta[109].sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = theta[109].sum()\n",
    "np.array([v / s for v in theta[109]]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X.mean(axis=0)\n",
    "means = [(i, means[0, i]) for i in range(means.shape[1]) if means[0, i] > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "n = len(means)\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(n / n_cols)\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(15, 20))\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    if i < len(means):\n",
    "        idx = means[i][0]\n",
    "        mu = means[i][1]\n",
    "        data = X[:,idx].toarray().reshape(1, -1)[0]\n",
    "        sns.distplot(data, ax=ax[i])\n",
    "        ax[i].set_title('w{}, mean={:.2f}'.format(idx, mu))\n",
    "        ax[i].set_ylabel('p')\n",
    "        ax[i].set_xlabel('count')\n",
    "    else:\n",
    "        ax[i].axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the pairwise correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = sorted([tup[0] for tup in means])\n",
    "df = pd.DataFrame(X[:, indices].toarray(), columns=['w{}'.format(i) for i in indices])\n",
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian mixture models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "U, S, V = svds(X, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def get_gmm_labels(X, k):\n",
    "    gmm = GaussianMixture(n_components=k, max_iter=200, random_state=37)\n",
    "    gmm.fit(X)\n",
    "    aic = gmm.aic(X)\n",
    "    bic = gmm.bic(X)\n",
    "    print('{}: aic={}, bic={}'.format(k, aic, bic))\n",
    "    return aic, bic, k, gmm\n",
    "\n",
    "gmm_scores = [get_gmm_labels(U, k) for k in range(2, 26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = gmm_scores[14][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = [s[2] for s in gmm_scores]\n",
    "_y = [s[0] for s in gmm_scores]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(_x, _y, color='tab:blue')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('aic')\n",
    "ax.set_title('AIC vs k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def get_kmc(X, k):\n",
    "    model = KMeans(k, random_state=37)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    print('{}: score={}'.format(k, score))\n",
    "    return score, k, model\n",
    "\n",
    "kmc_scores = [get_kmc(X, k) for k in range(2, 26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = [s[1] for s in kmc_scores]\n",
    "_y = [s[0] for s in kmc_scores]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(_x, _y, color='tab:blue')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('score')\n",
    "ax.set_title('Silhouette vs k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import LsiModel, LdaModel, HdpModel\n",
    "\n",
    "def dict_to_text(d):\n",
    "    def convert(p):\n",
    "        w = 'w{} '.format(p[0])\n",
    "        s = w * p[1]\n",
    "        s = s.strip()\n",
    "        return s\n",
    "    \n",
    "    pairs = list(d.items())\n",
    "    return ' '.join([convert(p) for p in pairs])\n",
    "        \n",
    "T = [dict_to_text(docs[i]).split(' ') for i in range(len(docs))]\n",
    "\n",
    "dictionary = corpora.Dictionary(T)\n",
    "corpus = [dictionary.doc2bow(text) for text in T]\n",
    "\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus_tfidf, id2word=dictionary, num_topics=15)\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "print(lsi.get_topics().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus, \n",
    "               id2word=dictionary, \n",
    "               num_topics=15, \n",
    "               random_state=37, \n",
    "               iterations=100,\n",
    "               per_word_topics=True)\n",
    "corpus_lda = lda[corpus]\n",
    "print(lda.get_topics().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp = HdpModel(corpus_tfidf, id2word=dictionary)\n",
    "corpus_hdp = hdp[corpus_tfidf]\n",
    "print(hdp.get_topics().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def tokenize_text(text, stop_words, stemmer):\n",
    "    def is_int(s):\n",
    "        try: \n",
    "            int(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "        \n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = filter(lambda t: len(t) > 2, tokens)\n",
    "    tokens = filter(lambda t: t not in stop_words, tokens)\n",
    "    tokens = filter(lambda t: is_int(t) is False, tokens)\n",
    "    tokens = map(lambda t: stemmer.stem(t), tokens)\n",
    "    return list(tokens)\n",
    "    \n",
    "docs = [\n",
    "    'The Art of Computer Programming',\n",
    "    'Computer Programming Learn Any Programming Language In 2 Hours',\n",
    "    'The Self-Taught Programmer The Definitive Guide to Programming Professionally',\n",
    "    'The Complete Software Developers Career Guide How to Learn Your Next Programming Language',\n",
    "    'Cracking the Coding Interview 189 Programming Questions and Solutions',\n",
    "    'The Economics Book Big Ideas Simply Explained',\n",
    "    'Economics in One Lesson The Shortest and Surest Way to Understand Basic Economics',\n",
    "    'Basic Economics',\n",
    "    'Aftermath Seven Secrets of Wealth Preservation in the Coming Chaos',\n",
    "    'Economics 101 From Consumer Behavior to Competitive Markets Everything You Need to Know About Economics'\n",
    "]\n",
    "tags = ('comp ' * 5).strip().split(' ') + ('econ ' * 5).strip().split(' ')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "documents = [TaggedDocument(tokenize_text(doc, stop_words, stemmer), [i]) \n",
    "                 for i, (doc, tag) in enumerate(zip(docs, tags))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(['art', 'comput', 'program'], [0])\n",
      "TaggedDocument(['comput', 'program', 'learn', 'program', 'languag', 'hour'], [1])\n",
      "TaggedDocument(['self-taught', 'programm', 'definit', 'guid', 'program', 'profession'], [2])\n",
      "TaggedDocument(['complet', 'softwar', 'develop', 'career', 'guid', 'learn', 'next', 'program', 'languag'], [3])\n",
      "TaggedDocument(['crack', 'code', 'interview', 'program', 'question', 'solut'], [4])\n",
      "TaggedDocument(['econom', 'book', 'big', 'idea', 'simpli', 'explain'], [5])\n",
      "TaggedDocument(['econom', 'one', 'lesson', 'shortest', 'surest', 'way', 'understand', 'basic', 'econom'], [6])\n",
      "TaggedDocument(['basic', 'econom'], [7])\n",
      "TaggedDocument(['aftermath', 'seven', 'secret', 'wealth', 'preserv', 'come', 'chao'], [8])\n",
      "TaggedDocument(['econom', 'consum', 'behavior', 'competit', 'market', 'everyth', 'need', 'know', 'econom'], [9])\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26749.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "vector_size = 5\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vector_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                workers=cpu_count,\n",
    "                dm=1)\n",
    "\n",
    "model.build_vocab([d for d in tqdm(documents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "max_epochs = 500\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train(shuffle([d for d in documents]), total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    model.alpha -= 0.0002\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [ 0.07805808 -0.00471411 -0.03416988  0.05626874 -0.02646747]\n"
     ]
    }
   ],
   "source": [
    "test_data = word_tokenize('Elements of Programming Interviews in Python The Insiders Guide'.lower())\n",
    "v1 = model.infer_vector(test_data, steps=20, alpha=0.025)\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.32205365 -0.91234583 -0.63008066  0.79771684 -0.99334589 -0.99121843\n",
      "  -0.18140417  0.92323718 -0.92079499 -0.98197714]\n",
      " [-0.31968745 -0.90218232 -0.62383598  0.78749905 -0.99378482 -0.99358022\n",
      "  -0.15476682  0.91378258 -0.92721101 -0.98421522]\n",
      " [-0.31422213 -0.89957183 -0.60021412  0.80191147 -0.99581106 -0.98857751\n",
      "  -0.19580523  0.93262018 -0.92368952 -0.9873972 ]\n",
      " [-0.26873803 -0.90076222 -0.62245437  0.80570971 -0.9971991  -0.98724518\n",
      "  -0.14962747  0.91921108 -0.91992753 -0.98167963]\n",
      " [-0.30895081 -0.89977726 -0.5946612   0.78127805 -0.99515865 -0.99278009\n",
      "  -0.19653136  0.91851479 -0.93453697 -0.98470567]\n",
      " [-0.30027906 -0.90255925 -0.58933573  0.79777547 -0.99393494 -0.98531753\n",
      "  -0.22599743  0.93245158 -0.92385817 -0.98224667]\n",
      " [-0.27294645 -0.89515616 -0.580418    0.80423611 -0.99462809 -0.9806002\n",
      "  -0.21866061  0.93341334 -0.92069549 -0.98119631]\n",
      " [-0.31011314 -0.88911392 -0.55471435  0.78494702 -0.99190371 -0.98371297\n",
      "  -0.24932135  0.9330635  -0.93104791 -0.98453912]\n",
      " [-0.22038311 -0.89985807 -0.60345284  0.80622873 -0.99331298 -0.97629098\n",
      "  -0.18537644  0.91804556 -0.91395987 -0.9703138 ]\n",
      " [-0.36338928 -0.90067574 -0.56705059  0.78341116 -0.9861659  -0.98420552\n",
      "  -0.27908295  0.93965969 -0.9253122  -0.9830049 ]]\n",
      "0.3383404612541199\n",
      "1.8148457407951355\n",
      "0.865681990981102\n",
      "1.954569160938263\n",
      "1.9470053315162659\n",
      "1.9093389511108398\n",
      "0.9647947028279305\n",
      "1.630157709121704\n",
      "1.078860491514206\n",
      "1.8867334723472595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X = np.array([model.docvecs[d.tags[0]] for d in documents], dtype=np.double)\n",
    "Y = np.array([model.infer_vector(d.words, steps=50) for d in documents], dtype=np.double)\n",
    "print(cosine_similarity(X, Y))\n",
    "\n",
    "for doc in documents:\n",
    "    trained = model.docvecs[doc.tags[0]]\n",
    "    inferred = model.infer_vector(doc.words, steps=20, alpha=0.025)\n",
    "    print(cosine(trained, inferred))  # cosine similarity from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.9839052557945251), (3, 0.9119670391082764), (2, 0.9066317677497864), (4, 0.8704017996788025), (9, 0.837632417678833), (8, 0.8258793354034424), (5, 0.7376419305801392), (7, 0.7004565596580505), (6, 0.6726831793785095)]\n"
     ]
    }
   ],
   "source": [
    "similar_doc = model.docvecs.most_similar(0)\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2742983   0.9502279  -0.99983233 -2.6495306  -2.0976636 ]\n"
     ]
    }
   ],
   "source": [
    "print(model.docvecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "* https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

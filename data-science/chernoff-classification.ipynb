{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "tr_df = pd.read_csv('./faces/data-train.csv')\n",
    "va_df = pd.read_csv('./faces/data-valid.csv')\n",
    "\n",
    "Data = namedtuple('Data', 'X y')\n",
    "T = Data(tr_df[[i for i in tr_df.columns if i != 'y']], tr_df['y'])\n",
    "V = Data(va_df[[i for i in va_df.columns if i != 'y']], va_df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Metric = namedtuple('Metric', 'clazz tn fp fn tp sen spe acc f1 auc')\n",
    "\n",
    "def get_classification_metrics(model, T, V):\n",
    "    def get_metrics(clazz, cmatrix):\n",
    "        tn, fp, fn, tp = cmatrix[0][0], cmatrix[0][1], cmatrix[1][0], cmatrix[1][1]\n",
    "        sen = tp / (tp + fn)\n",
    "        spe = tn / (tn + fp)\n",
    "        acc = (tp + tn) / (tp + fp + fn + tn)\n",
    "        f1 = (2.0 * tp) / (2 * tp + fp + fn)\n",
    "        return clazz, tn, fp, fn, tp, sen, spe, acc, f1\n",
    "    \n",
    "    model.fit(T.X, T.y)\n",
    "    y_pred = model.predict(V.X)\n",
    "    cmatrices = multilabel_confusion_matrix(V.y, y_pred)\n",
    "    \n",
    "    try:\n",
    "        clazzes = sorted(list(T.y.value_counts().index))\n",
    "    except:\n",
    "        clazzes = np.unique(T.y).astype(int)\n",
    "        \n",
    "    y_pred = model.predict_proba(V.X)\n",
    "    metrics = []\n",
    "    for clazz in clazzes:\n",
    "        clazz, tn, fp, fn, tp, sen, spe, acc, f1 = get_metrics(clazz, cmatrices[clazz])\n",
    "        y_true = [1 if y == clazz else 0 for y in V.y]\n",
    "        auc = roc_auc_score(y_true, y_pred[:,clazz])\n",
    "        metric = Metric(clazz, tn, fp, fn, tp, sen, spe, acc, f1, auc)\n",
    "        metrics.append(metric)\n",
    "    return metrics\n",
    "        \n",
    "def print_classification_metrics(metrics):\n",
    "    for m in metrics:\n",
    "        print('{}: sen = {:.5f}, spe = {:.5f}, acc = {:.5f}, f1 = {:.5f}, auc = {:.5f}'\n",
    "              .format(m.clazz, m.sen, m.spe, m.acc, m.f1, m.auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 0.82667, acc = 0.87000, f1 = 0.79365, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 0.74667, acc = 0.81000, f1 = 0.72464, auc = 1.00000\n",
      "2: sen = 0.72000, spe = 1.00000, acc = 0.93000, f1 = 0.83721, auc = 1.00000\n",
      "3: sen = 0.00000, spe = 1.00000, acc = 0.75000, f1 = 0.00000, auc = 0.66347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        LogisticRegression(random_state=37, multi_class='ovr', solver='newton-cg'), T, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 0.98667, acc = 0.99000, f1 = 0.98039, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "2: sen = 0.88000, spe = 0.93333, acc = 0.92000, f1 = 0.84615, auc = 0.98107\n",
      "3: sen = 0.76000, spe = 0.96000, acc = 0.91000, f1 = 0.80851, auc = 0.96720\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        RandomForestClassifier(n_estimators=100, random_state=37), T, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data to counter data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 19)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def sample(mvn, N=5000):\n",
    "    X = np.array([multivariate_normal.rvs(mean=mvn.mean, cov=mvn.cov) for _ in range(N)])\n",
    "    y = np.full((N, 1), mvn.clazz, dtype=np.int32)\n",
    "    return np.hstack([X, y])\n",
    "\n",
    "Mvn = namedtuple('Mvn', 'clazz mean cov')\n",
    "\n",
    "X_cols = [i for i in tr_df.columns if i != 'y']\n",
    "\n",
    "mvns = { clazz: Mvn(clazz, \n",
    "                    tr_df[tr_df['y'] == clazz][X_cols].mean().values, \n",
    "                    tr_df[tr_df['y'] == clazz][X_cols].cov().values) \n",
    "        for clazz in list(sorted(tr_df['y'].value_counts().index)) }\n",
    "\n",
    "S = np.vstack([sample(mvn) for mvn in mvns.values()])\n",
    "print(S.shape)\n",
    "\n",
    "X = S[:, 0:S.shape[1] - 1]\n",
    "y = S[:, S.shape[1] - 1]\n",
    "\n",
    "S = Data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression applied to sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "2: sen = 0.88000, spe = 0.97333, acc = 0.95000, f1 = 0.89796, auc = 0.99413\n",
      "3: sen = 0.92000, spe = 0.96000, acc = 0.95000, f1 = 0.90196, auc = 0.99093\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        LogisticRegression(random_state=37, multi_class='ovr', solver='newton-cg'), S, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest applied to sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "2: sen = 1.00000, spe = 0.97333, acc = 0.98000, f1 = 0.96154, auc = 0.99920\n",
      "3: sen = 0.92000, spe = 1.00000, acc = 0.98000, f1 = 0.95833, auc = 0.99840\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        RandomForestClassifier(n_estimators=100, random_state=37), S, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

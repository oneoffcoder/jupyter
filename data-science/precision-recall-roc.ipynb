{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "In this notebook, we will learn about constructing and interpreting precision-recall (PR) and receiver operating characteristic (ROC) curves. These curves are typically used to judge the performances of probabilistic classifiers beyond the confusion matrix and other performance measures that are derived from the confusion matrix. Note that the confusion matrix primarily judges categorical decisions, while PR and ROC curves are assessing probabilistic decisions. If a classifier does indeed make only categorical decisions (e.g. True or False, 1 or 0, yes or no, etc..), it may be sufficient to stick with a confusion matrix (although it is possible to turn categorical decisions to probabilistic ones, see [isotonic regression](https://en.wikipedia.org/wiki/Isotonic_regression)). \n",
    "\n",
    "However, oftentimes, a classifier makes probabilistic predictions (e.g. 80% True and 20% False, 75% 1 and 25% 0, 33% yes and 67% no, etc...) and the tragedy of judging classifier performance starts by choosing an arbitrary threshold (typically, > 50%) to categorize the prediction. For example, if a probabilistic classifier predicts True at 80%, one might say that the prediction is categorically True (since 80% > 50%); if a prediction is True at 49%, one might say that the prediction is categorically False (since 49% < 50%). The 50% cut-off is arbitrary, and one may choose any cut-off or threshold to impact the confusion matrix. With PR and ROC curves, the idea is to vary the cut-off from $[0, 1]$ and measure the performance over all these thresholds. In fact, after varying the cut-off, one may use PR and ROC curves to choose an optimal threshold to balance for trade-offs between precision vs recall or true positive rate (TPR) vs false positive rate (FPR). \n",
    "\n",
    "To understand PR and ROC curves, first understand the confusion matrix. Assume that there are only 2 classes to predict; True and False. Then a 2 x 2 matrix may be created such that the rows represent the predictions and the columns represent the truth. \n",
    "\n",
    "```\n",
    "+-------+------+-------+\n",
    "|       | True | False |\n",
    "+-------+------+-------+\n",
    "| True  | tp   | fp    |\n",
    "+-------+------+-------+\n",
    "| False | fn   | tn    |\n",
    "+-------+------+-------+\n",
    "```\n",
    "\n",
    "Each element in the confusion matrix stands for something.\n",
    "\n",
    "* tp is the number of true positive (model predicts the observation as true when the observation is really true)\n",
    "* fp is the number of false positive (model predicts the observation as true when the observation is really false)\n",
    "* fn is the number of false negative (model predicts the observation as false when the observation is really true)\n",
    "* tn is the number of true negative (model predicts the observation as false when the observation is really false)\n",
    "\n",
    "From these simple counts, a wonderful list of performance measures may be created (refer to the [Wikipedia site](https://en.wikipedia.org/wiki/Confusion_matrix)). Here, we only focus on precision, recall, TPR and FPR, which are defined as follows.\n",
    "\n",
    "* $\\text{precision}=\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$\n",
    "* $\\text{recall}=\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n",
    "* $\\text{TPR}=\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n",
    "* $\\text{FPR}=\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$\n",
    "\n",
    "Note that recall and TPR are the same thing and also referred to many other names (e.g. sensitivity).\n",
    "\n",
    "If a classifier is a probabilistic one, we may choose an arbitrary threshold, above which we will categorically say the prediction is True, to induce a confusion matrix and hence precision, recall, TPR and FPR. Changing the threshold will change the confusion matrix and hence, precision, recall, TPR and FPR (typically). We can `cheat` and choose one threshold to produce a set of desired precision, recall, TPR and FPR and report out that our classifier performs really well. However, we know better that we should look at these performance measures over all possible thresholds and report the aggregate (typically average) performance. The PR and ROC curves are visualizations of this operation, and the area under these curves (integrating over these curves) are the expected performance across all thresholds. \n",
    "\n",
    "The PR curve plots precision vs recall and we may observe the trade-off between the two; the ROC curve plots TPR vs FPR and we also observe the trade-off between the two. Note that precision, recall, TPR and FPR are scalar values that all lie in the range of $[0, 1]$. As such, the PR and ROC curves' domains in the x and y axis are also in the range $[0, 1]$. Meaning, the whole area is a square and a square with side length of 1 has an area of 1. This geometric understanding is important because when we draw the curve and integrate, the integration value will always be $[0, 1]$ where a lower value indicates `bad` performance and a higher value indicates `good` performance. However, the story is that simple. A `bad` curve typically integrates to 0.5, which means no better than guess; a `perfect` curve typically integrates to 1.0, which means never wrong. If a curve integrates to less than 0.5, the first impression is that the performance is worse than guess/chance. However, if we simply reverse the direction of decision, a really bad classifier can become a really good one. For example, if the area under the curve is 0.1, we may reverse our decision (e.g. turn True to False and False to True), and we should observe an area under the cruve of 0.9!\n",
    "\n",
    "# Simulate data\n",
    "\n",
    "Let's start out by simulating some data. We have 2 classes, 0 and 1, and we sample from 2 different multivariate gaussians.\n",
    "\n",
    "\n",
    "* $\\mu_0 = [1.5, 2.5, 3.3]$, $\\Sigma_0 = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$\n",
    "* $\\mu_1 = [1.7, 2.9, 3.0]$, $\\Sigma_1 = \\begin{bmatrix} 1.0 & 0.5 & 0.2 \\\\ 0.5 & 1.0 & 2.0 \\\\ 0.2 & 2.0 & 1.0 \\end{bmatrix}$\n",
    "\n",
    "We take 10,000 samples from each (total 20,000 samples) for training, `T`, and 25 samples from each (total 50 samples) for validation, `V`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from scipy.stats import multivariate_normal\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(37)\n",
    "\n",
    "MVN = namedtuple('MVN', 'mean cov')\n",
    "DATA = namedtuple('DATA', 'X, y')\n",
    "\n",
    "mvn0 = MVN(np.array([1.5, 2.5, 3.3]), np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]))\n",
    "mvn1 = MVN(np.array([1.7, 2.9, 3.0]), np.array([[1.0, 0.5, 0.2], [0.5, 1.0, 2.0], [0.2, 2.0, 1.0]]))\n",
    "\n",
    "N = 10000\n",
    "X0 = np.array([multivariate_normal.rvs(mvn0.mean, mvn0.cov) for _ in range(N)])\n",
    "X1 = np.array([multivariate_normal.rvs(mvn1.mean, mvn1.cov) for _ in range(N)])\n",
    "y0 = np.full((N, 1), 0, dtype=np.int32)\n",
    "y1 = np.full((N, 1), 1, dtype=np.int32)\n",
    "\n",
    "X = np.vstack([X0, X1])\n",
    "y = np.vstack([y0, y1])\n",
    "\n",
    "T = DATA(X, y)\n",
    "\n",
    "N = 25\n",
    "X0 = np.array([multivariate_normal.rvs(mvn0.mean, mvn0.cov) for _ in range(N)])\n",
    "X1 = np.array([multivariate_normal.rvs(mvn1.mean, mvn1.cov) for _ in range(N)])\n",
    "y0 = np.full((N, 1), 0, dtype=np.int32)\n",
    "y1 = np.full((N, 1), 1, dtype=np.int32)\n",
    "\n",
    "X = np.vstack([X0, X1])\n",
    "y = np.vstack([y0, y1])\n",
    "\n",
    "V = DATA(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn a classifier\n",
    "\n",
    "After we have our training `T` and validation `V` data, we plug in the data into a random forest classifier. We use the `predict_proba` function to retrieve the prediction probabilities of the validation example being 1 (or True). Below, `outcomes` is a list of tuples, where each tuple is a pair composed of the true label `y_t` and predicted label `y_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=37)\n",
    "rf_model.fit(T.X, T.y)\n",
    "\n",
    "y_pred = rf_model.predict_proba(V.X)[:,1]\n",
    "\n",
    "outcomes = sorted([(y_t, y_p) for y_t, y_p in zip(V.y[:,0], y_pred)], \n",
    "                  key=lambda tup: (-tup[1], -tup[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the precision-recall curve\n",
    "\n",
    "Now with `y_t, y_p`, we create count tp, fp and fn and compute precision and recall. Note that `get_pr()` computes the precision and recall for one threshold `t`, and that `get_prs` returns a list of precisions, recalls, and thresholds. To make a precision-recall curve, we use the `step` function. We make two precision-recall curves; one where the precision and recall values are computed from Scikit and another one where these values are computed using our own code.  This side-by-side comparison is just to show that we know how to compute and graph these precision-recall curves ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def get_pr(outcomes, t):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for y_t, y_p in outcomes:\n",
    "        clazz_t = int(y_t)\n",
    "        clazz_p = 1 if y_p >= t else 0\n",
    "        tp = tp + (1 if clazz_t == 1 and clazz_p == 1 else 0)\n",
    "        fp = fp + (1 if clazz_t == 0 and clazz_p == 1 else 0)\n",
    "        fn = fn + (1 if clazz_t == 1 and clazz_p == 0 else 0)\n",
    "\n",
    "    pre = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    return pre, rec\n",
    "\n",
    "def get_prs(outcomes, thresholds=np.linspace(0.2, 1, 9)):\n",
    "    pres = []\n",
    "    recs = []\n",
    "    thrs = []\n",
    "    for t in thresholds:\n",
    "        pre, rec = get_pr(outcomes, t)\n",
    "        pres.append(pre)\n",
    "        recs.append(rec)\n",
    "        thrs.append(t)\n",
    "    pres.append(1.0)\n",
    "    recs.append(0.0)\n",
    "    return np.array(pres), np.array(recs), np.array(thrs)\n",
    "\n",
    "pre_m, rec_m, _ = get_prs(outcomes, thresholds=np.linspace(0.2, 1, 100))\n",
    "pre_s, rec_s, _ = precision_recall_curve(V.y, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].step(rec_s, pre_s, color='b', alpha=0.2, where='post')\n",
    "ax[0].set_xlabel('recall')\n",
    "ax[0].set_ylabel('precision')\n",
    "ax[0].set_title('Scikit Precision-Recall Curve')\n",
    "\n",
    "ax[1].step(rec_m, pre_m, color='b', alpha=0.2, where='post')\n",
    "ax[1].set_xlabel('recall')\n",
    "ax[1].set_ylabel('precision')\n",
    "ax[1].set_title('Manual Precision-Recall Curve')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the precision-recall curve (using trapezoid method)\n",
    "\n",
    "Now we integrate over these curves.\n",
    "\n",
    "* `apr` is the average precision value computed from Scikit's API\n",
    "* `apr_s` is the average precision value computed from our code (precision and recall from Scikit)\n",
    "* `apr_m` is the average precision value computed from our code (precision and recall from our code)\n",
    "\n",
    "Note how they are off? Our code uses trapezoid integration which is optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apr = 0.70137, apr_s = 0.71357, apr_m = 0.71357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def get_apr(pre, rec):\n",
    "    x = np.flip(rec)\n",
    "    y = np.flip(pre)\n",
    "    return np.trapz(y, x)\n",
    "\n",
    "apr = average_precision_score(V.y, y_pred)\n",
    "apr_s = get_apr(pre_s, rec_s)\n",
    "apr_m = get_apr(pre_m, rec_m)\n",
    "\n",
    "print('apr = {:.5f}, apr_s = {:.5f}, apr_m = {:.5f}'.format(apr, apr_s, apr_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the precision-recall curve (using weighted average)\n",
    "\n",
    "Here, we use the suggested conservative integration approach and now all average percision agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apr = 0.70137, apr_s = 0.70137, apr_m = 0.70137\n"
     ]
    }
   ],
   "source": [
    "def get_apr(pre, rec):\n",
    "    x = np.flip(rec)\n",
    "    y = np.flip(pre)\n",
    "    \n",
    "    total = 0\n",
    "    for i in range(len(x)):\n",
    "        r_c = x[i]\n",
    "        r_p = x[i if i - 1 < 0 else i - 1]\n",
    "        p_i = y[i]\n",
    "        a = (r_c - r_p) * p_i\n",
    "        total = total + a\n",
    "    return total\n",
    "\n",
    "apr_s = get_apr(pre_s, rec_s)\n",
    "apr_m = get_apr(pre_m, rec_m)\n",
    "\n",
    "print('apr = {:.5f}, apr_s = {:.5f}, apr_m = {:.5f}'.format(apr, apr_s, apr_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the receiver operating characterics (ROC) curve\n",
    "\n",
    "We turn our attention to the ROC curve now. The algorithms for generating the data for PR and ROC curves are nearly identical and differ only in what we return. In PR, we return the precision and recall, but in ROC, we return TPR and FPR.\n",
    "\n",
    "One thing of interest is, if you have not noticed. Note that here, we pass in thresholds in a descending order and there is a 2 prepended to the thresholds in $[0, 1]$. The 2 prepended to the thresholds is easy to explain; it's simply there to level off the curve. The descending order of the thresholds makes the FPR vector sort in an increasing sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_fpr_tpr(outcomes, t):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for y_t, y_p in outcomes:\n",
    "        clazz_t = int(y_t)\n",
    "        clazz_p = 1 if y_p >= t else 0\n",
    "        tp = tp + (1 if clazz_t == 1 and clazz_p == 1 else 0)\n",
    "        fp = fp + (1 if clazz_t == 0 and clazz_p == 1 else 0)\n",
    "        fn = fn + (1 if clazz_t == 1 and clazz_p == 0 else 0)\n",
    "        tn = tn + (1 if clazz_t == 0 and clazz_p == 0 else 0)\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    return fpr, tpr\n",
    "\n",
    "def get_all_fpr_tpr(outcomes, thresholds=np.flip(np.append(np.linspace(0, 1, 11), [2]))):\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    thrs = []\n",
    "    for t in thresholds:\n",
    "        fpr, tpr = get_fpr_tpr(outcomes, t)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        thrs.append(t)\n",
    "    return np.array(fprs), np.array(tprs), np.array(thrs)\n",
    "\n",
    "fpr_m, tpr_m, t_m = get_all_fpr_tpr(outcomes, thresholds=np.flip(np.append(np.linspace(0, 1, 100), [2])))\n",
    "fpr_s, tpr_s, t_s = roc_curve(V.y, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].step(fpr_s, tpr_s, color='b', alpha=0.2, where='post')\n",
    "ax[0].set_xlabel('fpr')\n",
    "ax[0].set_ylabel('tpr')\n",
    "ax[0].set_title('Scikit ROC')\n",
    "\n",
    "ax[1].step(fpr_m, tpr_m, color='b', alpha=0.2, where='post')\n",
    "ax[1].set_xlabel('fpr')\n",
    "ax[1].set_ylabel('tpr')\n",
    "ax[1].set_title('Manual ROC')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the ROC curve (using trapezoid method)\n",
    "\n",
    "Here we use trapezoid integration over the ROC curves and observe that our manual approach agrees with Scikit's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc = 0.71200, auc_s = 0.71200, auc_m = 0.71200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_auc(tpr, fpr):\n",
    "    return np.trapz(tpr, fpr)\n",
    "\n",
    "auc = roc_auc_score(V.y, y_pred)\n",
    "auc_s = get_auc(tpr_s, fpr_s)\n",
    "auc_m = get_auc(tpr_m, fpr_m)\n",
    "\n",
    "print('auc = {:.5f}, auc_s = {:.5f}, auc_m = {:.5f}'.format(auc, auc_s, auc_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
